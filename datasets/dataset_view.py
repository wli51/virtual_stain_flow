"""
datasets/dataset_view.py

Core Dataset Infrastructure for dynamically loading image from files in
a lazy-loading fashion.

"""
from __future__ import annotations
from pathlib import Path, PurePath
from collections import OrderedDict
from typing import List, Optional, Sequence
from dataclasses import dataclass, field

import numpy as np
import pandas as pd
from PIL import Image

"""
Minimal view defining the immutable component of a dataset.
Simply holds a file index containing pathlike where each row corresponds to a
view/fov/sample and columns corresponds to channels associated with that entry,
and a PIL image mode to use when reading images.
"""
@dataclass(frozen=True)
class DatasetView:
    file_index: pd.DataFrame
    pil_image_mode: str = "I;16"

    def __post_init__(self) -> None:
        if not isinstance(self.file_index, pd.DataFrame) or self.file_index.empty:
            raise ValueError("file_index must be a non-empty DataFrame.")
        

        if not isinstance(self.pil_image_mode, str):
            raise ValueError("Expected pil_image_mode to be a string, "
                             f"got {type(self.pil_image_mode)} instead.")
        if self.pil_image_mode not in Image.MODES:
            raise ValueError(f"Invalid pil_image_mode: {self.pil_image_mode}. "
                             f"Must be one of {Image.MODES.keys()}.")
        
        fi = self.file_index
        arr = fi.to_numpy(dtype=object).ravel()
        if not all(isinstance(x, (Path, PurePath, str)) for x in arr):
                bad = [type(x).__name__ for x in arr \
                       if not isinstance(x, (Path, PurePath, str))]
                raise TypeError(f"file_index has non-path-like entries: {set(bad)}")
    
    def __len__(self) -> int:
        """
        Return the number of rows in the file index.
        """
        return len(self.file_index)
    
    @property
    def n_channels(self) -> int:
        """
        Return the number of columns in the file index.
        """
        return len(self.file_index.columns)

    def get_paths_for_keys(self, idx: int, keys: Sequence[str]) -> List[Path]:
        """
        Return file paths (ordered to match keys) for a given row index.
        """
        row = self.file_index.iloc[idx]
        out = []
        for k in (keys or []):
            v = row[k]
            # v is guaranteed path-like after __post_init__
            p = v if isinstance(v, Path) else Path(v)
            out.append(p)
        return out

    def read_image(self, path: Path) -> np.ndarray:
        """
        Read a single image and convert to configured PIL mode, then to ndarray.
        """
        if not path.exists():
            raise FileNotFoundError(f"File not found: {path}")
        try:
            with Image.open(path) as img:
                img = img.convert(self.pil_image_mode)
                arr = np.asarray(img)
        except Exception as e:
            raise RuntimeError(f"Error reading image from {path}: {e}") from e

        if arr.ndim not in (2, 3):
            raise ValueError(f"Unsupported image shape {arr.shape} from {path}")
        return arr

"""
Minimal tracker for index state to associate with a DatasetView.
More orderly than just maintaining dataset_class._index.
Intended to be utilized by dataset classes as internal memory
for last loaded image index to allow for retrieval of relevant
metadata.
"""
@dataclass
class IndexState:
    last: Optional[int] = None

    def reset(self) -> None:
        self.last = None

    def is_stale(self, idx: Optional[int]) -> bool:
        return self.last is None or idx is None or self.last != idx

    def update(self, idx: int) -> None:
        if self.is_stale(idx):
            self.last = idx

"""
Lazy file state tracker to associate with a DatasetView.
This tracks the current input/target image np arrays and paths and 
determines when to invoke the DatasetView to read images in a lazy manner, 
minimizing redundant reads. Also centralizes the optional LRU caching logic.
"""
@dataclass
class FileState:
    view: DatasetView
    # Current realized state (order corresponds to last request)
    input_paths: List[Path] = field(default_factory=list)
    target_paths: List[Path] = field(default_factory=list)
    input_image_raw: Optional[np.ndarray] = None  # (C, H, W) or (C, H, W, K)
    target_image_raw: Optional[np.ndarray] = None

    # Global cache of decoded channels by path (optional LRU)
    cache_capacity: Optional[int] = None
    _cache: "OrderedDict[Path, np.ndarray]" = field(
        default_factory=OrderedDict, init=False)
    
    def __post_init__(self) -> None:
        if self.cache_capacity is None:
            self.cache_capacity = self.view.n_channels
        # Validate sentinel
        if self.cache_capacity < -1:
            raise ValueError("cache_capacity must be -1 (unbounded) or >= 0.")
        # Optional: guard against 0 (almost always a footgun)
        if self.cache_capacity == 0:
            raise ValueError("cache_capacity=0 disables caching; set 1+ or -1.")

    def reset(self) -> None:
        self.input_paths.clear()
        self.target_paths.clear()
        self.input_image_raw = None
        self.target_image_raw = None

    # ---- internal cache helpers ----
    def _touch_cache(self, path: Path, arr: np.ndarray) -> None:
        
        # unbounded cache, since we never evict cached item
        # and the View defining all image files constituting
        # the dataset is immutable, eventually all images
        # will be cached and memory usage will persist until
        # process end.
        if self.cache_capacity == -1:
            self._cache[path] = arr
            return
        
        # bounded LRU
        cap = self.cache_capacity
        if path in self._cache:
            # LRU logic: move cache hit to end (most recently used position)
            self._cache.move_to_end(path)
        self._cache[path] = arr
        while len(self._cache) > cap:
            self._cache.popitem(last=False)  # evict least recently used

    def _get_or_load(self, path: Path) -> np.ndarray:
        arr = self._cache.get(path)
        if arr is None:
            arr = self.view.read_image(path)
            self._touch_cache(path, arr)
        else:
            # refresh LRU position if using capacity
            if self.cache_capacity is not None and self.cache_capacity > 0:
                self._cache.move_to_end(path)
        return arr

    def _ensure_same_spatial_shape(self, arrays: List[np.ndarray], paths: List[Path]) -> None:
        if not arrays:
            return
        ref_shape = arrays[0].shape[:2]  # H, W from (H,W) or (H,W,K)
        for a, p in zip(arrays, paths):
            if a.shape[:2] != ref_shape:
                raise ValueError(
                    f"Spatial shape mismatch: {p} has {a.shape[:2]}, expected {ref_shape}"
                )

    def _stack_channels(self, arrays: List[np.ndarray]) -> np.ndarray:
        """
        Stack as (C, H, W) for 2D planes, 
        or (C, H, W, K) if planes are multi-channel (e.g., RGB).
        """
        if not arrays:
            # Return empty with zero channels? Usually caller ensures non-empty.
            return np.empty((0,))
        sample = arrays[0]
        if sample.ndim == 2:
            # (H, W) -> (C, H, W)
            return np.stack(arrays, axis=0)
        elif sample.ndim == 3:
            # (H, W, K) -> (C, H, W, K)
            return np.stack(arrays, axis=0)
        else:
            raise ValueError(f"Unsupported per-channel array ndim={sample.ndim}")

    # ---- public update API ----
    def update(
        self,
        idx: int,
        input_keys: Sequence[str],
        target_keys: Sequence[str],
    ) -> None:
        """
        Lazily realize current input/target stacks for an index and channel config.
        Only load missing paths; reuse and reorder already-cached ones.
        """
        # Resolve desired paths (order matters)
        desired_input_paths = self.view.get_paths_for_keys(idx, input_keys)
        desired_target_paths = self.view.get_paths_for_keys(idx, target_keys)

        # Load/reuse inputs
        input_arrays: List[np.ndarray] = []
        for p in desired_input_paths:
            input_arrays.append(self._get_or_load(p))

        # Load/reuse targets
        target_arrays: List[np.ndarray] = []
        for p in desired_target_paths:
            target_arrays.append(self._get_or_load(p))

        # Validate shapes before stacking (optional but safer)
        self._ensure_same_spatial_shape(input_arrays, desired_input_paths)
        self._ensure_same_spatial_shape(target_arrays, desired_target_paths)

        # Stack in requested order
        self.input_image_raw = self._stack_channels(input_arrays) if input_arrays else None
        self.target_image_raw = self._stack_channels(target_arrays) if target_arrays else None

        # Record the realized order
        self.input_paths = desired_input_paths
        self.target_paths = desired_target_paths